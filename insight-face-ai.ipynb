{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e85620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import insightface\n",
    "import os\n",
    "import onnxruntime\n",
    "import onnx\n",
    "import cv2\n",
    "import threading\n",
    "import cv2\n",
    "import numpy\n",
    "import numpy as np\n",
    "from deepface import DeepFace\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26b971ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = [onnxruntime.get_available_providers()[0]]\n",
    "reference_face_position = 0\n",
    "similar_face_distance = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c4d7a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "inswapper-shape: [1, 3, 128, 128]\n"
     ]
    }
   ],
   "source": [
    "swapper = insightface.model_zoo.get_model(\"inswapper_128.onnx\", providers=provider)\n",
    "lock = threading.Lock()\n",
    "face_annalyser = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63894e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annalyser():\n",
    "    global face_annalyser\n",
    "    with lock:\n",
    "        if face_annalyser is None:\n",
    "            face_annalyser = insightface.app.FaceAnalysis(name='buffalo_l', providers=provider)\n",
    "            face_annalyser.prepare(ctx_id=0)\n",
    "    return face_annalyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c56c5157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_many_faces(frame):\n",
    "    try:\n",
    "        return annalyser().get(frame)\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b4bb0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_face(frame, position = 0):\n",
    "    many_faces = get_many_faces(frame)\n",
    "    if many_faces:\n",
    "        try:\n",
    "            return many_faces[position]\n",
    "        except IndexError:\n",
    "            return many_faces[-1]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3a8bf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_face(frame, reference_face):\n",
    "    many_faces = get_many_faces(frame)\n",
    "    if many_faces:\n",
    "        for face in many_faces:\n",
    "            if hasattr(face, 'normed_embedding') and hasattr(reference_face, 'normed_embedding'):\n",
    "                distance = numpy.sum(numpy.square(face.normed_embedding - reference_face.normed_embedding))\n",
    "                if distance < similar_face_distance:\n",
    "                    return face\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96756c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(source_face, reference_face, temp_frame):\n",
    "    target_face = find_similar_face(temp_frame, reference_face)\n",
    "    if target_face:\n",
    "        try:\n",
    "            temp_frame = swapper.get(temp_frame, target_face, source_face, paste_back=True)\n",
    "        except:\n",
    "            print(\"Face not found in the image provided\")\n",
    "#             Exception handinling for wrong face\n",
    "    return temp_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f883ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap(new_face,image): \n",
    "    source_face = get_one_face(new_face)\n",
    "    target_frame = image\n",
    "    reference_face = get_one_face(target_frame, reference_face_position)\n",
    "    result = process_frame(source_face, reference_face, target_frame)\n",
    "    plt.imshow(result[:,:,::-1])\n",
    "    plt.show()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05933573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return face from an image in a required aspect ration\n",
    "def face_image_resize(img, w,h):\n",
    "    detected_faces = DeepFace.analyze(img, actions = [\"gender\"], enforce_detection=False)\n",
    "    detected = False\n",
    "    detected_face = img\n",
    "    if len(detected_faces) > 0:\n",
    "        for temp_img in detected_faces[:1]:\n",
    "            x = max(temp_img[\"region\"][\"x\"] - 50, 0)\n",
    "            y = max(temp_img[\"region\"][\"y\"] - 50, 0)\n",
    "            w = temp_img[\"region\"][\"w\"] + 100\n",
    "            h = temp_img[\"region\"][\"h\"] + 100\n",
    "            detected_face = img[y:y+h, x:x+w]\n",
    "            detected = True\n",
    "    new_image = cv2.resize(detected_face, (w, h))\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd51105a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def replace_face(path, images=[]):\n",
    "    # Loading the image to be edited\n",
    "    img = cv2.imread(path)\n",
    "    # Idntifying all the faces and the gender of the person using deepface\n",
    "    obj = DeepFace.analyze(img, actions = [\"gender\"])\n",
    "    # Printing out the gender along with the faces detected\n",
    "    temp_obj = []\n",
    "    i = 0\n",
    "    test = \"\"\n",
    "    face = \"\"\n",
    "    for temp_img in obj:\n",
    "        sub_path = \"\"\n",
    "        if len(images) > i:\n",
    "            sub_path = images[i]\n",
    "        elif len(images) == i:\n",
    "            i = 0\n",
    "            sub_path = f'static/{i}.jpg'\n",
    "        else:\n",
    "            sub_path = f'static/{i}.jpg'\n",
    "        xo = temp_img[\"region\"][\"x\"]\n",
    "        yo = temp_img[\"region\"][\"y\"]\n",
    "        wo = temp_img[\"region\"][\"w\"]\n",
    "        ho = temp_img[\"region\"][\"h\"]\n",
    "        x = max(temp_img[\"region\"][\"x\"] - 50, 0)\n",
    "        y = max(temp_img[\"region\"][\"y\"] - 50, 0)\n",
    "        w = temp_img[\"region\"][\"w\"] + 100\n",
    "        h = temp_img[\"region\"][\"h\"] + 100\n",
    "        print(\"Gender : \" + temp_img[\"dominant_gender\"])\n",
    "        print(\"Face : \")\n",
    "        test = img[y:y+h, x:x+w]\n",
    "        plt.imshow(img[y:y+h, x:x+w][:,:,::-1])\n",
    "        plt.show()\n",
    "        if bool(int(input(\"Change face 0/1? \"))):\n",
    "            print(f'using {sub_path}')\n",
    "            face = face_image_resize(cv2.imread(sub_path), w,h)\n",
    "            new_face_image = swap(face, test)\n",
    "            img[y:y+h, x:x+w] = new_face_image\n",
    "            i = i + 1\n",
    "        print(\"\")\n",
    "    cv2.imwrite(\"output.jpg\", img)\n",
    "    print(\"image saved\")\n",
    "    plt.imshow(img[:,:,::-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ac7e44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
